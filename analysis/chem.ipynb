{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('../../nn_physical_concepts')\n",
    "\n",
    "from scinet import *\n",
    "import scinet.ed_oscillator as edo\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Times'],'size' : 16})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#extract generated data\n",
    "df = pd.read_csv('../data/transient_data_ch41step.csv')\n",
    "\n",
    "#extract forward rates\n",
    "df_rates = pd.read_csv('../data/constant_data_ch41step.csv')\n",
    "kf = np.zeros((1,2001))\n",
    "for i in range(2001):\n",
    "    kf[0,i] = float(df_rates['kf'][i][1:-1])\n",
    "kf = kf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts data from pandas format to scinet format with 3 observations\n",
    "def my_load_traindata_3(df,thalf = 1.25e-5):\n",
    "    mydf = df[df['t [s]'] <=thalf]\n",
    "    in1 = np.zeros((2001*25,25))\n",
    "    in2 = np.zeros((2001*25,3))\n",
    "    out = np.zeros((2001*25,1))\n",
    "    for j in range(25):\n",
    "        for i in range(1000,3001):\n",
    "            in1[(i-1000)*25 + j,:] = mydf[mydf['T [K]']==i]['Yco2']\n",
    "    in2[:,0] = mydf['t [s]']\n",
    "    in2[:,1] = mydf['Yo2']\n",
    "    in2[:,2] = mydf['Ych4']\n",
    "    out[:,0] = mydf['Yco2']\n",
    "    return [in1, in2, out]\n",
    "#converts data from pandas format to scinet format with 3 observations at a specific T\n",
    "def my_load_testdata3(df,T,thalf = 1.25e-5 ):\n",
    "    mydf = df[df['t [s]'] <= thalf]\n",
    "    in1 = np.zeros((51,25))\n",
    "    in2 = np.zeros((51,3))\n",
    "    for i in range(51): \n",
    "        in1[i,:] = mydf[mydf['T [K]']==T]['Yco2']\n",
    "        in2[i,0] = i*5e-7\n",
    "    in2[:,1] = df[df['T [K]']==T]['Yo2']\n",
    "    in2[:,2] = df[df['T [K]']==T]['Ych4']\n",
    "    out = np.zeros((51,1))\n",
    "    return [in1,in2,out]\n",
    "\n",
    "#randomizes and splits data to train test and dev sets\n",
    "def my_train_test_split(train_data3,test_size = 0.25,random_state=42):\n",
    "    in1train, in1tmp = train_test_split(train_data3[0], test_size=test_size, random_state=random_state)\n",
    "    in2train, in2tmp = train_test_split(train_data3[1], test_size=test_size, random_state=random_state)\n",
    "    outtrain, outtmp = train_test_split(train_data3[2], test_size=test_size, random_state=random_state)\n",
    "    in1test, in1dev = train_test_split(in1tmp, test_size=0.5, random_state=random_state)\n",
    "    in2test, in2dev = train_test_split(in2tmp, test_size=0.5, random_state=random_state)\n",
    "    outtest, outdev = train_test_split(outtmp, test_size=0.5, random_state=random_state)\n",
    "    return [in1train,in2train,outtrain],[in1test,in2test,outtest],[in1dev,in2dev,outdev]\n",
    "\n",
    "#randomizes and splits temperature to train test and dev sets\n",
    "def my_temp_train_test_split(test_size = 0.25,random_state=42):\n",
    "    temp = np.arange(1000,3001)\n",
    "    temptrain, temptmp = train_test_split(temp, test_size=test_size, random_state=random_state)\n",
    "    temptest, tempdev = train_test_split(temptmp, test_size=0.5, random_state=random_state)\n",
    "    return temptrain, temptest, tempdev\n",
    "\n",
    "\n",
    "#converts data from pandas format to scinet format with 3 observations at a single T and time\n",
    "def my_load_testdata_singletime(df,T,time,thalf = 1.25e-5 ):\n",
    "    mydf = df[df['t [s]'] <= thalf]\n",
    "    in1 = np.zeros((1,25))\n",
    "    in2 = np.zeros((1,3))\n",
    "    in1[0,:] = mydf[mydf['T [K]']==T]['Yco2']\n",
    "    in2[0,0] = time\n",
    "    in2[:,1] = df[(df['T [K]']==T) & (df['t [s]']<(time+4e-7))& (df['t [s]']>(time-4e-7))]['Yo2']\n",
    "    in2[:,2] = df[(df['T [K]']==T) & (df['t [s]']<(time+4e-7))& (df['t [s]']>(time-4e-7))]['Ych4']\n",
    "    out = np.zeros((1,1))\n",
    "    return [in1,in2,out]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pandas to scinet input\n",
    "train_data3  = my_load_traindata_3(df,thalf = 1.25e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "td, vd, test_data  = my_train_test_split(train_data3) #randomise and split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize net\n",
    "net = nn.Network(latent_size = 3,input_size =  25,input2_size = 3,output_size = 1,encoder_num_units= [500, 100],name = 'Prod1') #initialize net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize training\n",
    "\n",
    "train_losses = []\n",
    "dev_losses = []\n",
    "\n",
    "#Training program\n",
    "#procedure summary: 1000 epochs with alpha 1e-3, batch 512; 500 epochs with alpha 1e-4 batch 1024, 500 epochs with alpha 1e-5 batch 1024\n",
    "num_phases = 3\n",
    "all_epochs         = [100, 100,  100 ]\n",
    "all_batches        = [32,  32, 32]\n",
    "all_learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "myBeta = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print_frequency = 0.1\n",
    "\n",
    "for j in tqdm.tqdm_notebook(range(num_phases)):\n",
    "    num_epochs = all_epochs[j]\n",
    "    batch_size = all_batches[j]\n",
    "    learning_rate = all_learning_rates[j]\n",
    "    check_epochs = int(print_frequency * num_epochs)\n",
    "    \n",
    "    for i in tqdm.tqdm_notebook(range(num_epochs)):\n",
    "        net.train(1, batch_size, learning_rate, td, vd, beta_fun=(lambda x: myBeta), test_step=10 )\n",
    "\n",
    "        # Check progress. It is recommended to use Tensorboard instead for this.\n",
    "        train_recon_error = net.run(td, net.recon_loss)\n",
    "        train_kl_loss     = net.run(td, net.kl_loss)\n",
    "        train_loss        = train_recon_error + myBeta*train_kl_loss\n",
    "\n",
    "        dev_recon_error   = net.run(vd, net.recon_loss)\n",
    "        dev_kl_loss       = net.run(vd, net.kl_loss)\n",
    "        dev_loss          = dev_recon_error + myBeta*dev_kl_loss\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        dev_losses.append(dev_loss)\n",
    "\n",
    "        if i%check_epochs == 0:\n",
    "            print(\"Training: (loss, reconstruction error, kl loss): ({:.2e}, {:.2e}, {:.2e})\".format(\n",
    "            train_loss, train_recon_error, train_kl_loss))\n",
    "            print(\"Dev:      (loss, reconstruction error, kl loss): ({:.2e}, {:.2e}, {:.2e})\".format(\n",
    "            dev_loss, dev_recon_error, dev_kl_loss))\n",
    "            print(\"=======================================\")\n",
    "\n",
    "    print(\"{} epochs trained so far\".format(net.tot_epochs) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocess Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss vs Epoch\n",
    "\n",
    "plt.semilogy(range(300),train_losses,'b',label='training loss')\n",
    "plt.semilogy(range(300),dev_losses,'r',label='dev loss')\n",
    "plt.semilogy(range(300),abs(np.array(train_losses)-np.array(dev_losses)),'g',label='difference')\n",
    "plt.legend()\n",
    "plt.xlim(0,300)\n",
    "plt.xlabel(r'\\# Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for test set\n",
    "t = np.arange(51)*5e-1 #mus\n",
    "T = 1000\n",
    "plt.plot([12.5,12.5],[0,0.6],'k--')\n",
    "\n",
    "tT, vt, Ttest  = my_temp_train_test_split()\n",
    "\n",
    "for T in Ttest[::25]: \n",
    "    test_data = my_load_testdata3(df,T)\n",
    "    a_precicted = net.run(test_data, net.output).ravel()\n",
    "    plt.plot(t,a_precicted,label = r'T = '+str(T))\n",
    "\n",
    "    plt.plot(t,df[df['T [K]']==T]['Yco2'],'k--', dashes= (1,10),label='_nolegend_',linewidth = 2)\n",
    "\n",
    "plt.plot([-1],[-1],'k',label ='Truth')\n",
    "\n",
    "plt.plot(-1,-1,'k.',label='Predicted')\n",
    "\n",
    "plt.legend(loc='center right',bbox_to_anchor = (1.4,0.5))\n",
    "plt.xlim((0,25))\n",
    "plt.ylim((0,0.6))\n",
    "plt.text(3,0.55,'Observation data')\n",
    "plt.text(15.5,0.55,'Answer data')\n",
    "plt.ylabel(r'$Y_{\\textrm{CO2}}$')\n",
    "plt.xlabel(r'Time [$\\mu$s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretable temperatures\n",
    "\n",
    "t = np.arange(51)*5e-1 #mus\n",
    "T = 1000\n",
    "\n",
    "Ttest = [1000,1200,1400,1800,2000,3000]\n",
    "\n",
    "for T in Ttest: \n",
    "    test_data = my_load_testdata3(df,T)\n",
    "    a_precicted = net.run(test_data, net.output).ravel()\n",
    "    plt.plot(t,a_precicted,label = r'T = '+str(T))\n",
    "    \n",
    "plt.fill_between(t, df[df['T [K]']==1400]['Yco2'],  df[df['T [K]']==1800]['Yco2'],color='lightblue')\n",
    "plt.text(10,0.3,'Interpretable region')\n",
    "plt.legend(loc='center right',bbox_to_anchor = (1.4,0.5))\n",
    "plt.xlim((0,25))\n",
    "plt.ylim((0,0.6))\n",
    "plt.ylabel(r'$Y_{\\textrm{CO2}}$')\n",
    "plt.xlabel(r'Time [$\\mu$s]')\n",
    "plt.savefig('chem_interp_co2.png',dpi=400,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate latent space\n",
    "latentspace = np.zeros((101,3))\n",
    "time = 1.5e-5\n",
    "for T in range(1000,3001,20):\n",
    "    latentspace[(T-1000)/20,:] = np.array([net.run(my_load_testdata_singletime(df,T,time), net.mu)[0] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretable latent space\n",
    "\n",
    "\n",
    "plt.fill_between([1400,1800],[-15e-6,-15e-6],[17e-6,17e-6],color='lightblue')\n",
    "\n",
    "plt.plot(range(1000,3001,20),latentspace[:,0],label = 'Neuron 1')\n",
    "plt.plot(range(1000,3001,20),latentspace[:,1],label ='Neuron 2')\n",
    "plt.plot(range(1000,3001,20),latentspace[:,2],label ='Neuron 3')\n",
    "\n",
    "plt.ylabel('Latent activation')\n",
    "plt.plot([1400,1400],[17e-6,-15e-6],'k--')\n",
    "plt.plot([1800,1800],[17e-6,-15e-6],'k--')\n",
    "plt.ylim([-15e-6,17e-6])\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$T$ [K]')\n",
    "plt.xlim([1000,3000])\n",
    "# plt.xticks([0,5e5,1e6,1.5e6,2e6])\n",
    "plt.savefig('chem_interp_latent.png',dpi=400,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latent space vs T\n",
    "\n",
    "plt.plot(range(1000,3001,20),latentspace[:,0],label = 'Neuron 1')\n",
    "plt.plot(range(1000,3001,20),latentspace[:,1],label ='Neuron 2')\n",
    "plt.plot(range(1000,3001,20),latentspace[:,2],label ='Neuron 3')\n",
    "\n",
    "plt.ylabel('Latent activation')\n",
    "\n",
    "plt.ylim([-15e-6,17e-6])\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$T$ [K]')\n",
    "plt.xlim([1000,3000])\n",
    "# plt.xticks([0,5e5,1e6,1.5e6,2e6])\n",
    "plt.savefig('chem_interp_latent.png',dpi=400,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latent space vs kf\n",
    "\n",
    "plt.plot(kf[0:2001:20],latentspace[:,0],label = 'Neuron 1')\n",
    "plt.plot(kf[0:2001:20],latentspace[:,1],label ='Neuron 2')\n",
    "plt.plot(kf[0:2001:20],latentspace[:,2],label = 'Neuron 3')\n",
    "plt.ylabel('Latent activation')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$k_f$')\n",
    "plt.xlim([kf[400],kf[700]])\n",
    "plt.ylim([-6e-7,6e-7])\n",
    "plt.savefig('chem_latent.png',dpi=400,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
