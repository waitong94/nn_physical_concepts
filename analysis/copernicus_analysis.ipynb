{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scinet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-889f2594494e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscinet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscinet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0med_copernicus\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0medc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scinet'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from scinet import *\n",
    "import scinet.ed_copernicus as edc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_jumps(theta_M):\n",
    "    \"\"\"\n",
    "    Fixes jumps that arise because theta_M is always between -pi and pi\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        diff = np.abs(theta_M[:, 1:] - theta_M[:, :-1])\n",
    "        jumps = np.array(np.where(diff > 1.)).T\n",
    "        if len(jumps) == 0:\n",
    "            break\n",
    "        fixed_lines = []\n",
    "        for x, y in jumps:\n",
    "            if x in fixed_lines:\n",
    "                continue\n",
    "            else:\n",
    "                fixed_lines.append(x)\n",
    "            theta_M[x, y + 1:] = theta_M[x, y + 1:] - np.sign(theta_M[x, y + 1] - theta_M[x, y]) * 2 * np.pi\n",
    "    return theta_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copernicus_phi(net, series_length=20, delta_t=7, steps=50):\n",
    "    layer = net.state_means\n",
    "    ss = np.linspace(0, 2 * np.pi, num=steps)\n",
    "    mm = np.linspace(0, 2 * np.pi, num=steps)\n",
    "    S, M = np.meshgrid(ss, mm)\n",
    "    data = edc.copernicus_data(series_length, delta_t=delta_t, phi_S_target=np.ravel(S), phi_M_target=np.ravel(M))[0]\n",
    "    fig = plt.figure(figsize=(6.0, 2.8))\n",
    "    fig.tight_layout()\n",
    "    out = np.array(net.run(data, layer))\n",
    "    for i in range(len(out[0])):\n",
    "        zs = out[:, i]\n",
    "        ax = fig.add_subplot('12{}'.format(i+1), projection='3d')\n",
    "        ax.view_init(20, 60)\n",
    "        Z = np.reshape(zs, S.shape)\n",
    "        surf = ax.plot_surface(S, M, Z, rstride=1, cstride=1, cmap=cm.inferno, linewidth=0)\n",
    "        ax.set_xlabel(r'$\\phi_S$')\n",
    "        ax.set_ylabel(r'$\\phi_M$')\n",
    "        ax.set_zlabel('Latent activation {}'.format(i + 1))\n",
    "        ax.set_xticks([0, np.pi, 2*np.pi])\n",
    "        ax.set_yticks([0, np.pi, 2*np.pi])\n",
    "        ax.set_xticklabels(['0', r'$\\pi$', r'$2 \\pi$'])\n",
    "        ax.set_yticklabels(['0', r'$\\pi$', r'$2 \\pi$'])\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_fit(net, series_length, steps=100):\n",
    "    R_E = 1.\n",
    "    R_M = 1.524\n",
    "\n",
    "    dist = lambda theta_S, theta_M: R_E * np.cos(theta_S - theta_M) + np.sqrt(R_M**2 - R_E**2 * np.sin(theta_S - theta_M)**2)\n",
    "    phi_E = lambda theta_S, theta_M: theta_S\n",
    "    phi_M = lambda theta_S, theta_M: np.angle(R_E / R_M * np.cos(theta_S) - dist(theta_S, theta_M) / R_M * np.cos(theta_M) +\n",
    "                                              1.j * (R_E / R_M * np.sin(theta_S) - dist(theta_S, theta_M) / R_M * np.sin(theta_M)))\n",
    "    theta_S_range = [0, 2 * np.pi]\n",
    "    theta_M_range = [-np.pi, np.pi]\n",
    "\n",
    "    theta_S, theta_M = np.meshgrid(np.linspace(*theta_S_range, num=steps), np.linspace(*theta_M_range, num=steps))\n",
    "\n",
    "    in_theta = np.vstack([np.ravel(theta_S), np.ravel(theta_M)]).T\n",
    "    in_zero = np.zeros([np.size(theta_S), (2 * series_length - 2)]) # padding to get right shape of input\n",
    "\n",
    "    net_in = np.hstack([in_theta, in_zero])\n",
    "    zs = net.run(net_in, net.state_means)\n",
    "\n",
    "    phi_E_vals = phi_E(theta_S, theta_M)\n",
    "    phi_M_vals = fix_jumps(phi_M(theta_S, theta_M).T).T\n",
    "\n",
    "    coeffs = [] # coefficients for fitting the network output to a linear combination of phi_E and phi_M\n",
    "    for i in range(2):\n",
    "        A = np.vstack([np.ravel(phi_E_vals), np.ravel(phi_M_vals), np.ones(np.size(theta_S))]).T\n",
    "        coeffs.append(np.linalg.lstsq(A, zs[:, i], rcond=None)[0])\n",
    "\n",
    "    fig = plt.figure(figsize=(16.4, 12.2))\n",
    "    for i in range(2):\n",
    "        ax = fig.add_subplot('22{}'.format(2 * i + 1), projection='3d')\n",
    "        ax.plot_surface(theta_S, theta_M, zs[:, i].reshape(theta_M.shape), cmap=cm.inferno)\n",
    "        ax.set_xlabel(r'$\\theta_S$')\n",
    "        ax.set_ylabel(r'$\\theta_M$')\n",
    "        ax.set_zlabel('Latent activation {}'.format(i + 1))\n",
    "        ax = fig.add_subplot('22{}'.format(2 * i + 2), projection='3d')\n",
    "        fit_z = coeffs[i][0] * phi_E_vals + coeffs[i][1] * phi_M_vals + coeffs[i][2]\n",
    "        ax.plot_surface(theta_S, theta_M, fit_z, cmap=cm.inferno)\n",
    "        ax.set_xlabel(r'$\\theta_S$')\n",
    "        ax.set_ylabel(r'$\\theta_M$')\n",
    "        ax.set_zlabel(r'Fit ${:.2} \\, \\phi_E + {:.2} \\, \\phi_M + {:.2}$'.format(*coeffs[i]))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model\n",
    "\n",
    "### Parameters\n",
    "- `latent_size: 2`\n",
    "- `input_size: 1` \n",
    "- `output_size: 2`\n",
    "- other parameters: default values\n",
    "### Data\n",
    "- random_start: False (uses realistic data that could have been collected during Copernicus' lifetime)\n",
    "- Training data: 95000 samples with `delta_t: 7`\n",
    "- Validation data: 5000 samples with `delta_t: 7`\n",
    "\n",
    "### Training\n",
    "1. 1000 epochs with `batch_size: 256`, `learning_rate: 1e-4`, `beta: 0.1`, `euler_l2_coeff: 1`, `time_series_length: 20`\n",
    "2. 1000 epochs with `batch_size: 1024`, `learning_rate: 1e-4`, `beta: 0.1`, `euler_l2_coeff: 1`, `time_series_length: 20`\n",
    "3. 1000 epochs with `batch_size: 1024`, `learning_rate: 1e-4`, `beta: 0.1`, `euler_l2_coeff: 1`, `time_series_length: 50`\n",
    "4. 1000 epochs with `batch_size: 2048`, `learning_rate: 1e-5`, `beta: 0.01`, `euler_l2_coeff: 1`, `time_series_length: 50`\n",
    "5. 11000 epochs with `batch_size: 2048`, `learning_rate: 1e-5`, `beta: 0.001`, `euler_l2_coeff: 1`, `time_series_length: 50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Network.from_saved('copernicus', change_params={'name': 'copernicus'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of latent activation as a function of observed angles\n",
    "\n",
    "Each row of the following plots corresponds to one latent neuron. Within each row, the plot on the left shows the activation of this latent neuron as a function of the observed angled $\\theta_S$ and $\\theta_M$. The right plot shows a fit of the latent activation to a linear combination $\\phi_S(\\theta_S, \\theta_M)$, $\\phi_M(\\theta_S, \\theta_M)$ (see Fig. 6a in paper for the definition of $\\theta$ and $\\phi$). The fact that the plots within every row look similar confirms again that SciNet has learnt a linear combination of the heliocentric angles $\\phi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "theta_fit(net, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of latent activation as a function of heliocentric angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "fig = copernicus_phi(net, series_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate L2-norm of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, states = edc.copernicus_data(50, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(net.run(data, net.recon_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
